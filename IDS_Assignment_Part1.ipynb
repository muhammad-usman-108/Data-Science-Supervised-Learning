{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The First Part of the Assignment of IDS 2019-2020\n",
    "Document your results as well as the way you obtained them in this jupyter notebook. A seperate report (pdf, word etc.) is _not_ required. However, it is necessary that you provide the python code leading to your results as well as textual answers to the assignment questions in this notebook. *DO NOT CLEAR THE OUTPUT of the notebook your are submitting!* In the cases that the result of an algorithm is pdf, jpg, etc, you should attach the result to this notebook file and refer to that in the text.  \n",
    "\n",
    "Next to the jupyter notebook, submit one zip-file containing all data sets that you are asked to submit. Make sure they are easily identifiable, i.e. use names as requested in the corresponding question.\n",
    "\n",
    "Do not change the general structure of this notebook, but you can add further markdown or code cells to explain your solutions if necessary. In the end, submit this file and your created data sets in moodle.\n",
    "\n",
    "Only <font color=\"red\">one </font> group member should upload your group's solution. *Make sure to include group members' names and matriculation numbers*. If your name and student id are not included in the report, you will not receive any points!\n",
    "\n",
    "\n",
    "Hint 1: While answering the questions, you will get a better and better impression of the given data. However, feel free to compute additional results and vizualizations to motivate the decisions you need to make, for example with respect to modification, simplification or sampling of the data. <font color=\"red\"><b>Ensure that all claims you make are supported by the presented facts!</b></font>\n",
    "\n",
    "Hint 2: <font color=\"red\"><b>Some of the tasks might need some time to run. Take this into account in your planning.</b></font>\n",
    "\n",
    "Hint 3: RWTHonline allows for multiple submissions (each submission overwrites the previous ones). <font color=\"red\"><b>Partial submissions are possible and encouraged. </b></font> This helps in case of technical problems of RWTHonline, which do seldomly happen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\"><b>Student Names and IDs:\n",
    "    1. Muhammad Usman (Matriculation Number : 407503)\n",
    "    2. Yashab Faryal (Matriculation Number : )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of the Dataset (5 points)\n",
    " You should carry out some preprocessing steps before starting the analysis:\n",
    " - Select 90% of 'population_density' dataset by random sampling.\n",
    "     - Use one of the group member's student number as a seed.\n",
    " - Add another column to the dataset:\n",
    "     - Name it 'population_density_categorical'.\n",
    "     - The values in this column depend on values in 'population_density' column and will be defined as follows:\n",
    "        - 5824=<population density              corresponding value in 'population_density_categorical' column: 'very high'\n",
    "        - 4368=<population density<5824         corresponding value in 'population_density_categorical' column: 'high'\n",
    "        - 2912=<population density<4368         corresponding value in 'population_density_categorical' column: 'medium'\n",
    "        - 1456=<population density<2912         corresponding value in 'population_density_categorical' column: 'low' \n",
    "        - population density<1456               corresponding value in 'population_density_categorical' column: 'very low'\n",
    " - After completing this preprocessing step, export your final dataset as 'population_density_categorical.csv' dataset and use that for next steps of the assignment.\n",
    " - If it is not directly mentioned, you should always use your extracted (above-created) dataset (without any cleaning).\n",
    " - <font color='red'>Important!</font> Make sure that you submit your extracted dataset with your result in moodle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      holiday  temperature  rain_1h  snow_1h  clouds_percentage weather_type  \\\n",
      "21340    None       272.55     0.00      0.0                 40       Clouds   \n",
      "13808    None       288.43     0.00      0.0                 75       Clouds   \n",
      "38768    None       274.22     0.00      0.0                  1        Clear   \n",
      "20846    None       269.95     0.00      0.0                 90         Snow   \n",
      "22942    None       284.28     0.00      0.0                 90      Drizzle   \n",
      "17886    None       296.83     1.27      0.0                 75         Rain   \n",
      "26678    None       288.58     0.00      0.0                  1        Clear   \n",
      "29214    None       260.65     0.00      0.0                 90         Snow   \n",
      "44640    None       290.55     0.00      0.0                  5         Rain   \n",
      "10859    None       263.41     0.00      0.0                 64       Clouds   \n",
      "33799    None       279.02     0.00      0.0                  1        Clear   \n",
      "14910    None       291.78     0.00      0.0                  0        Clear   \n",
      "6290     None       286.93     0.00      0.0                 90         Rain   \n",
      "10289    None       274.81     0.00      0.0                 64         Haze   \n",
      "4238     None       274.59     0.00      0.0                 90      Drizzle   \n",
      "12025    None       255.48     0.00      0.0                 90       Clouds   \n",
      "18928    None       287.47     0.00      0.0                  1        Clear   \n",
      "41334    None       258.80     0.00      0.0                  1        Clear   \n",
      "26694    None       292.16     0.00      0.0                  1        Clear   \n",
      "22457    None       297.48     0.00      0.0                  1        Clear   \n",
      "12062    None       255.08     0.00      0.0                 20       Clouds   \n",
      "23919    None       289.77     0.00      0.0                  1         Rain   \n",
      "16026    None       296.23     0.55      0.0                 40         Rain   \n",
      "31806    None       274.83     0.00      0.0                 90      Drizzle   \n",
      "46904    None       295.21     0.00      0.0                 75       Clouds   \n",
      "38605    None       271.75     0.00      0.0                  1        Clear   \n",
      "5268     None       274.03     0.00      0.0                 90         Snow   \n",
      "32360    None       281.82     0.00      0.0                 40         Mist   \n",
      "6808     None       288.12     0.00      0.0                 88       Clouds   \n",
      "27993    None       278.89     0.00      0.0                  1        Clear   \n",
      "...       ...          ...      ...      ...                ...          ...   \n",
      "8808     None       303.84     0.00      0.0                  1        Clear   \n",
      "45047    None       303.68     0.00      0.0                 75       Clouds   \n",
      "3635     None       270.47     0.00      0.0                 75         Haze   \n",
      "38685    None       278.15     0.00      0.0                 90         Mist   \n",
      "1901     None       268.41     0.00      0.0                 90         Snow   \n",
      "39916    None       273.22     0.00      0.0                 40       Clouds   \n",
      "4367     None       269.69     0.00      0.0                 90       Clouds   \n",
      "32449    None       287.27     0.00      0.0                  1        Clear   \n",
      "11528    None       265.11     0.00      0.0                 64         Haze   \n",
      "28984    None       261.68     0.00      0.0                 90         Mist   \n",
      "26591    None       285.94     0.00      0.0                  1        Clear   \n",
      "30507    None       270.95     0.00      0.0                 90       Clouds   \n",
      "48069    None       283.94     0.25      0.0                 90      Drizzle   \n",
      "26392    None       295.94     0.00      0.0                 75      Drizzle   \n",
      "40228    None       251.23     0.00      0.0                 75       Clouds   \n",
      "37717    None       281.76     0.00      0.0                  1        Clear   \n",
      "5447     None       273.61     0.00      0.0                 90         Mist   \n",
      "26526    None       287.92     0.00      0.0                  1        Clear   \n",
      "40650    None       263.41     0.00      0.0                 90         Snow   \n",
      "23921    None       289.47     0.00      0.0                 90      Drizzle   \n",
      "23678    None       291.50     1.40      0.0                 90         Rain   \n",
      "20528    None       258.99     0.00      0.0                 90         Mist   \n",
      "22018    None       271.29     0.00      0.0                  1        Clear   \n",
      "12814    None       280.58     0.00      0.0                 40       Clouds   \n",
      "10580    None       258.93     0.00      0.0                 64       Clouds   \n",
      "28356    None       273.95     0.00      0.0                 90         Mist   \n",
      "35905    None       286.08     0.00      0.0                 90      Drizzle   \n",
      "11698    None       250.39     0.00      0.0                  5        Clear   \n",
      "44731    None       293.51     0.00      0.0                 90       Clouds   \n",
      "2247     None       270.52     0.00      0.0                 90         Snow   \n",
      "\n",
      "              weather_type_details         date_time  population_density  \\\n",
      "21340             scattered clouds   2/16/2016 17:00                6009   \n",
      "13808                broken clouds   4/20/2014 23:00                1132   \n",
      "38768                 sky is clear   11/8/2017 12:00                4585   \n",
      "20846                   light snow    1/26/2016 1:00                 314   \n",
      "22942                      drizzle   4/30/2016 20:00                3347   \n",
      "17886                moderate rain     9/2/2015 2:00                 325   \n",
      "26678                 sky is clear    9/17/2016 3:00                 391   \n",
      "29214                   light snow   12/17/2016 4:00                 333   \n",
      "44640         heavy intensity rain    6/2/2018 22:00                2808   \n",
      "10859                broken clouds   12/22/2013 1:00                 765   \n",
      "33799                 sky is clear    5/19/2017 7:00                6490   \n",
      "14910                 Sky is Clear     6/5/2014 8:00                6045   \n",
      "6290                    light rain   5/22/2013 16:00                6702   \n",
      "10289                         haze   12/2/2013 11:00                4584   \n",
      "4238       light intensity drizzle    3/11/2013 1:00                 362   \n",
      "12025              overcast clouds    2/5/2014 10:00                4212   \n",
      "18928                 sky is clear   10/11/2015 5:00                 327   \n",
      "41334                 sky is clear    2/7/2018 21:00                2463   \n",
      "26694                 sky is clear   9/17/2016 19:00                3592   \n",
      "22457                 sky is clear   4/14/2016 18:00                4686   \n",
      "12062                   few clouds    2/6/2014 23:00                1250   \n",
      "23919                   light rain    6/3/2016 23:00                1999   \n",
      "16026                moderate rain   6/26/2015 18:00                4416   \n",
      "31806      light intensity drizzle   3/16/2017 22:00                2857   \n",
      "46904                broken clouds   8/21/2018 16:00                6229   \n",
      "38605                 sky is clear    11/3/2017 4:00                 842   \n",
      "5268                    heavy snow    4/19/2013 2:00                 261   \n",
      "32360                         mist     4/4/2017 0:00                 561   \n",
      "6808               overcast clouds    6/8/2013 22:00                3254   \n",
      "27993                 sky is clear  11/11/2016 10:00                4478   \n",
      "...                            ...               ...                 ...   \n",
      "8808                  sky is clear    9/6/2013 18:00                5199   \n",
      "45047                broken clouds   6/17/2018 14:00                4192   \n",
      "3635                          haze   2/15/2013 10:00                4742   \n",
      "38685                         mist    11/5/2017 4:00                 287   \n",
      "1901                    heavy snow  12/10/2012 22:00                1684   \n",
      "39916             scattered clouds   12/19/2017 8:00                5791   \n",
      "4367               overcast clouds   3/18/2013 21:00                1966   \n",
      "32449                 sky is clear    4/7/2017 14:00                5464   \n",
      "11528                         haze   1/16/2014 12:00                4631   \n",
      "28984                         mist  12/10/2016 17:00                4340   \n",
      "26591                 sky is clear   9/13/2016 22:00                1688   \n",
      "30507              overcast clouds    1/26/2017 7:00                6368   \n",
      "48069      light intensity drizzle   9/25/2018 14:00                4973   \n",
      "26392                      drizzle    9/6/2016 13:00                4294   \n",
      "40228                broken clouds  12/30/2017 21:00                2271   \n",
      "37717                 sky is clear    10/4/2017 4:00                 860   \n",
      "5447                          mist   4/23/2013 19:00                3181   \n",
      "26526                 sky is clear    9/11/2016 8:00                2265   \n",
      "40650                   light snow   1/14/2018 22:00                2292   \n",
      "23921      light intensity drizzle     6/4/2016 0:00                1259   \n",
      "23678  light intensity shower rain   5/27/2016 10:00                4507   \n",
      "20528                         mist    1/9/2016 12:00                4984   \n",
      "22018                 sky is clear    3/25/2016 2:00                 391   \n",
      "12814             scattered clouds   3/10/2014 10:00                4122   \n",
      "10580                broken clouds  12/10/2013 15:00                5540   \n",
      "28356                         mist   11/23/2016 3:00                 378   \n",
      "35905      light intensity drizzle    8/3/2017 11:00                4693   \n",
      "11698                 sky is clear   1/23/2014 12:00                4499   \n",
      "44731              overcast clouds    6/6/2018 12:00                5098   \n",
      "2247                    heavy snow  12/20/2012 21:00                2458   \n",
      "\n",
      "      population_density_categorical  \n",
      "21340                      very high  \n",
      "13808                       very low  \n",
      "38768                           high  \n",
      "20846                       very low  \n",
      "22942                         medium  \n",
      "17886                       very low  \n",
      "26678                       very low  \n",
      "29214                       very low  \n",
      "44640                            low  \n",
      "10859                       very low  \n",
      "33799                      very high  \n",
      "14910                      very high  \n",
      "6290                       very high  \n",
      "10289                           high  \n",
      "4238                        very low  \n",
      "12025                         medium  \n",
      "18928                       very low  \n",
      "41334                            low  \n",
      "26694                         medium  \n",
      "22457                           high  \n",
      "12062                       very low  \n",
      "23919                            low  \n",
      "16026                           high  \n",
      "31806                            low  \n",
      "46904                      very high  \n",
      "38605                       very low  \n",
      "5268                        very low  \n",
      "32360                       very low  \n",
      "6808                          medium  \n",
      "27993                           high  \n",
      "...                              ...  \n",
      "8808                            high  \n",
      "45047                         medium  \n",
      "3635                            high  \n",
      "38685                       very low  \n",
      "1901                             low  \n",
      "39916                           high  \n",
      "4367                             low  \n",
      "32449                           high  \n",
      "11528                           high  \n",
      "28984                         medium  \n",
      "26591                            low  \n",
      "30507                      very high  \n",
      "48069                           high  \n",
      "26392                         medium  \n",
      "40228                            low  \n",
      "37717                       very low  \n",
      "5447                          medium  \n",
      "26526                            low  \n",
      "40650                            low  \n",
      "23921                       very low  \n",
      "23678                           high  \n",
      "20528                           high  \n",
      "22018                       very low  \n",
      "12814                         medium  \n",
      "10580                           high  \n",
      "28356                       very low  \n",
      "35905                           high  \n",
      "11698                           high  \n",
      "44731                           high  \n",
      "2247                             low  \n",
      "\n",
      "[43384 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Your code:\n",
    "import pandas as pd\n",
    "#path of the file\n",
    "data_url = 'D:\\\\Google Drive\\\\RWTH\\\\Introduction To Data Science\\\\Assignment Part 1\\\\population_density.csv'\n",
    "\n",
    "# read data from csv file as pandas dataframe\n",
    "df = pd.read_csv(data_url)\n",
    "\n",
    "# frac=0.9 which means 90% selection of data using random sampling\n",
    "# random_state is used as seed (Here I am using my Matriculation No. as required)\n",
    "df_percent = df.sample(frac=0.9, random_state=407503)\n",
    "\n",
    "population_density_categorical = []\n",
    "\n",
    "for i in range(0,len(df_percent[\"population_density\"])):\n",
    "    if (df_percent.iloc[i][\"population_density\"] >= 5824):\n",
    "        population_density_categorical.append(\"very high\")\n",
    "    elif (df_percent.iloc[i][\"population_density\"] >= 4368 and df_percent.iloc[i][\"population_density\"]<5824):\n",
    "        population_density_categorical.append(\"high\")\n",
    "    elif (df_percent.iloc[i][\"population_density\"] >= 2912 and df_percent.iloc[i][\"population_density\"]<4368):\n",
    "        population_density_categorical.append(\"medium\")\n",
    "    elif (df_percent.iloc[i][\"population_density\"] >= 1456 and df_percent.iloc[i][\"population_density\"]<2912):\n",
    "        population_density_categorical.append(\"low\")\n",
    "    elif (df_percent.iloc[i][\"population_density\"] < 1456):\n",
    "        population_density_categorical.append(\"very low\")\n",
    "\n",
    "df_percent[\"population_density_categorical\"] = population_density_categorical\n",
    "\n",
    "print(df_percent)\n",
    "export_csv = df_percent.to_csv (r'D:\\\\Google Drive\\\\RWTH\\\\Introduction To Data Science\\\\Assignment Part 1\\\\population_density_categorical.csv') \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 - Insights into the Data (20 points):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Outliers (10 points)\n",
    "   (a) Use a boxplot to find and remove the outliers from \"temperature\". Note that based on the boxplot the values greater than upper-whisker and less than lower-whisker are considered as the outliers. Now you should  have two datasets (cleaned and original)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (b) Compare basic statistical features of \"temperature\" (median, mean, and mode) in the cleaned and original datasets.    Interpret the differences for these statistical values between the cleaned and original datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (c) Compare the number of data rows before and after removing the outliers. How many data rows are removed by removing    outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Visualization (10 points)\n",
    "   (d) Visualize mean and median of \"population_density\" for non-'None' \"holiday\" values in the original dataset. Specify    the \"holiday\" values for which the mean of \"population_density\" is maximal and for which it is minimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (e) Plot the distribution of \"temperature\" in the original and cleaned datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (f) Explore the distribution of \"population_density\" and \"temperature\" together in the cleaned dataset. Specify the ranges of \"temperature\" and \"population_density\" for which the frequency of the data is the highest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 - Decision Trees (15 points):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (a) Add a categorical temperature column to the cleaned dataset based on the following rules and name it                \"temperature_categorical\":\n",
    "        - temperature >= upper_quartile (third quartile) corresponding value in 'temperature_categorical' column: 'high'\n",
    "        - temperature <= lower_quartile (first quartile) corresponding value in 'temperature_categorical' column: 'low'\n",
    "        - lower_quartile < temperature < upper_quartile corresponding value in 'temperature_categorical' column: 'medium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (b) In the new dataset (created in Section 'a'), consider \"holiday\", \"temperature_categorical\", and \"weather_type\" as    the descriptive features and \"population_density_categorical\" as the target feature. Set the minimum number of samples  for splitting to 5000 and make a decision tree based on entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (c) What is the best attribute (based on entropy) for splitting the tree in the second round of ID3?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 - Regression (10 points):\n",
    "\n",
    "For this question (Q3), restrict your extracted data set to the columns *holiday, temperature, rain_1h, snow_1h, clouds_percentage, date_time* and *population_density*. Drop the information on the date for *date_time* and restrict the data to time values (hour) only.\n",
    "\n",
    "We define *population_density* to be our target feature, while all other features are considered descriptive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (a) Which features are suitable as an input for linear regression and which need to be modified first? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (b) Implement and briefly motivate an adequate modification. Print the resulting data set limited to the first two data rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) To get a first idea about our data, plot the behaviour of the target feature (population_density) over time (date_time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (d) Create two distinct subsets of the data. Use sampling methods as described in the lecture. You should end up with two DIFFERENT sample data sets *RegA, RegB*. Include these data sets in the submitted data set zip file. \n",
    "   \n",
    "   Which sampling methods did you choose and why? Which one do you expect to result in a better classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (e) Train a linear regression classifier based on each of the two sample data sets *RegA, RegB* created before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) Visualize both computed regression functions in one plot each, combined with the original data set. For example, you can show a plot similar to 3(c) and insert the regression functions result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (g) For each of the two resulting models compute and print the mean squared error, mean absolute error and median squared error with respect to the original, non-sampled data set. Also, present plots showing the errors and squared errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (h) Interpret and evaluate the two models and compare them. Why are they similar/different? Which model do you recommend and why? How do you think the applied methods could be improved to get better results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 - Support Vector Machines (10 points):\n",
    "\n",
    "For this question (Q4), restrict your extracted data set to the columns *holiday, temperature, rain_1h, snow_1h, clouds_percentage, date_time* and *population_density_categorical*. For *date_time*, drop the information on the date and restrict the data to time values only.\n",
    "We define *population_density_categorical* to be our target feature, while all other features are considered descriptive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (a) Which features are suitable as an input for SVM and which need to be modified first? Modify the data as needed and provide a brief explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (b) Divide the data set into a training set *svmTrain* and a test set *svmTest* and briefly motivate your division      strategy. Include these data sets in the data set zip file you submit. \n",
    "   \n",
    "   Hint: Training the SVMs will take longer for a large training set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (c) Use the training set to train 3 different SVMs with different combinations of the parameters. Use at least two distinct values for the parameters *kernel* and *C*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (d) Compute and print the mean accurracy and classification report of the trained SVMs with respect to the test set (as shown in instruction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (e) Interpret and evaluate the 3 SVMs and compare them. Why are they similar/different? Which SVM do you recommend and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 - Neural Networks (20 points)\n",
    "In this question consider the whole dataset that you have created in the *Preprocessing of Dataset* section. The target feature is *population_density_categorical*. \n",
    "\n",
    "To avoid performance problems, use the first 4000 rows of your dataset (you will need 2000 for training and 2000 for testing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (a) What are the possible inputs of your network?\n",
    "     - Show the possible extracted features.\n",
    "     - Show the number of possible patterns of inputs for the categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (b) Before using the Neural Network algorithm, do you think it provides an accurate result? Why? \n",
    "     - Your explanation should be supported by data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (c) Which features can be used for designing your network as inputs? Why?\n",
    "       - Which features should be changed (example: from categorical to numerical or numerical to categorical)? Why? \n",
    "       - Convert the features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (d) Train your network with default hyperparameters and return the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (e) Try to find an optimized number of hidden layers and nodes. \n",
    "      - Start with default numbers and then at least go with one number above and one number below the default.\n",
    "      - Use the 2000 rows of the data for training.\n",
    "      - What are the optimized numbers of hidden layers and nodes that you have found?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code: (number of hidden layers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code: (number of nodes in the hidden layer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code: (optimized network) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (f) Try to train your model with one linear activation function and one non-linear activation function. Use the default number of hidden layers and nodes.\n",
    "     - Name the functions and explain how the results are different and why. \n",
    "     - You can use evaluation metrics to show which activation function works better for this data set.\n",
    "     - Use the 2000 rows of the data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code: (linear activation function):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code: (non-linear activation function):\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6 - Evaluation (10 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (a) Consider one of the models in question 4 (c) of your choice, one neural network with optimized number of hidden layers and nodes from question 5 (e), and the neural network with non-linear activation function from question 5 (f), for a total of *three* models, together with their respective datasets. Compute the following metrics for a 3-fold cross validation performed on each model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Confusion matrices on the training data (sum cell-by-cell the results of each fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for the confusion matrices on the training data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Confusion matrices on the test data (sum cell-by-cell the results of each fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for the confusion matrices on the test data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Precision, recall and F1-scores on the test data (give explicitly the result for each fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for precision, recall and F1-scores on the test data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy scores on training and test data (give explicitly the result for each fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for accuracy scores on training and test data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to turn numbers into insights, please comment on your findings. Motivate the answers to the following questions using the metrics and the findings in the questions 1 through 5 of the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (b) What is, in your opinion, the best model? Motivate your answer with the correct performance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (c) Does any model suffer from underfitting or overfitting? Motivate your answer with the correct performance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   (d) What is the effect of employing cross validation, instead of simply holding our a certain percentage of examples as test/validation set? What are the advantages and disadvantages of cross validation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
